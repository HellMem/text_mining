{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input phrases\n",
    "phrases = [\"The car is clean and bright\",\n",
    "           \"The car is old and good\",\n",
    "           \"I love to have my kitchen clean\",\n",
    "           \"I need to clean all the dishes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.41101031, 0.52131446, 0.41101031, 0.33274827,\n",
       "         0.        , 0.        , 0.        , 0.41101031, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.33274827,\n",
       "         0.        ],\n",
       "        [0.        , 0.38144133, 0.        , 0.38144133, 0.        ,\n",
       "         0.        , 0.48380996, 0.        , 0.38144133, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.48380996, 0.30880963,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.28462634,\n",
       "         0.        , 0.        , 0.44592216, 0.        , 0.44592216,\n",
       "         0.44592216, 0.44592216, 0.        , 0.        , 0.        ,\n",
       "         0.35157015],\n",
       "        [0.4747708 , 0.        , 0.        , 0.        , 0.30304005,\n",
       "         0.4747708 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.4747708 , 0.        , 0.30304005,\n",
       "         0.37431475]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to vector\n",
    "vectorizer     = TfidfVectorizer()  \n",
    "bow = vectorizer.fit_transform(phrases)\n",
    "bow.shape\n",
    "vectorizer.get_feature_names()\n",
    "#browse to dense vectors\n",
    "bow.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tf_idf_weights\n",
      "all            1.916291\n",
      "bright         1.916291\n",
      "dishes         1.916291\n",
      "good           1.916291\n",
      "have           1.916291\n",
      "kitchen        1.916291\n",
      "love           1.916291\n",
      "my             1.916291\n",
      "need           1.916291\n",
      "old            1.916291\n",
      "and            1.510826\n",
      "car            1.510826\n",
      "is             1.510826\n",
      "to             1.510826\n",
      "clean          1.223144\n",
      "the            1.223144\n"
     ]
    }
   ],
   "source": [
    "# compute td-idf\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_bow=tfidf_transformer.fit(bow)\n",
    "\n",
    "# print idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=vectorizer.get_feature_names(),columns=[\"tf_idf_weights\"])\n",
    " \n",
    "# sort desc\n",
    "tfidf_sorted =df_idf.sort_values(by=['tf_idf_weights'],ascending=False)\n",
    "print (tfidf_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create SVD\n",
    "svd= TruncatedSVD(n_components=2)\n",
    "lsa = svd.fit_transform(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    topic_1   topic_2                             body\n",
      "0  0.862029 -0.200194      The car is clean and bright\n",
      "1  0.801410 -0.391736          The car is old and good\n",
      "2  0.271234  0.765596  I love to have my kitchen clean\n",
      "3  0.459537  0.606823   I need to clean all the dishes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#print (lsa)\n",
    "topics_df = pd.DataFrame(lsa,columns=[\"topic_1\",\"topic_2\"])\n",
    "topics_df[\"body\"] = phrases\n",
    "print (topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           topic1    topic2\n",
      "all      0.130636  0.250980\n",
      "and      0.395183 -0.201851\n",
      "bright   0.269079 -0.090917\n",
      "car      0.395183 -0.201851\n",
      "clean    0.301359  0.291998\n",
      "dishes   0.130636  0.250980\n",
      "good     0.232161 -0.165106\n",
      "have     0.072421  0.297408\n",
      "is       0.395183 -0.201851\n",
      "kitchen  0.072421  0.297408\n",
      "love     0.072421  0.297408\n",
      "my       0.072421  0.297408\n",
      "need     0.130636  0.250980\n",
      "old      0.232161 -0.165106\n",
      "the      0.403319 -0.003218\n",
      "to       0.160093  0.432355\n"
     ]
    }
   ],
   "source": [
    "#looking at the word\n",
    "\n",
    "word_matrix = pd.DataFrame(svd.components_,index=['topic1','topic2'],columns=dic).T\n",
    "print(word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_matrix['abs_topic1'] = np.abs(word_matrix[\"topic1\"])\n",
    "word_matrix['abs_topic2'] = np.abs(word_matrix[\"topic2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           topic1    topic2  abs_topic1  abs_topic2\n",
      "the      0.403319 -0.003218    0.403319    0.003218\n",
      "and      0.395183 -0.201851    0.395183    0.201851\n",
      "car      0.395183 -0.201851    0.395183    0.201851\n",
      "is       0.395183 -0.201851    0.395183    0.201851\n",
      "clean    0.301359  0.291998    0.301359    0.291998\n",
      "bright   0.269079 -0.090917    0.269079    0.090917\n",
      "good     0.232161 -0.165106    0.232161    0.165106\n",
      "old      0.232161 -0.165106    0.232161    0.165106\n",
      "to       0.160093  0.432355    0.160093    0.432355\n",
      "all      0.130636  0.250980    0.130636    0.250980\n",
      "dishes   0.130636  0.250980    0.130636    0.250980\n",
      "need     0.130636  0.250980    0.130636    0.250980\n",
      "have     0.072421  0.297408    0.072421    0.297408\n",
      "kitchen  0.072421  0.297408    0.072421    0.297408\n",
      "love     0.072421  0.297408    0.072421    0.297408\n",
      "my       0.072421  0.297408    0.072421    0.297408\n"
     ]
    }
   ],
   "source": [
    "print (word_matrix.sort_values('abs_topic1',ascending=False))\n",
    "#print (word_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
